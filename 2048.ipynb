{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a81bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from game2048.board2048 import Board2048\n",
    "from stable_baselines3 import PPO\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "758f25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "from game2048.board2048 import Board2048\n",
    "\n",
    "\n",
    "class Board2048Renderer(Board2048):\n",
    "    def __init__(self, cell_size=100, margin=5, font_size=36, rendering_mode=None):\n",
    "        super().__init__()\n",
    "        self.cell_size = cell_size\n",
    "        self.margin = margin\n",
    "        self.width = 4 * (cell_size + margin) + margin\n",
    "        self.height = self.width\n",
    "        self.colors = self._generate_colors()\n",
    "        self.rendering_mode = rendering_mode\n",
    "\n",
    "        if self.rendering_mode == 'human':\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "            pygame.display.set_caption(\"2048\")\n",
    "            self.font = pygame.font.Font(None, font_size)\n",
    "\n",
    "    def _generate_colors(self):\n",
    "        \"\"\"Generate a dictionary of colors for different tile values.\"\"\"\n",
    "        colors = {\n",
    "            0: (205, 193, 180),  # Empty cell\n",
    "            2: (238, 228, 218),\n",
    "            4: (237, 224, 200),\n",
    "            8: (242, 177, 121),\n",
    "            16: (245, 149, 99),\n",
    "            32: (246, 124, 95),\n",
    "            64: (246, 94, 59),\n",
    "            128: (237, 207, 114),\n",
    "            256: (237, 204, 97),\n",
    "            512: (237, 200, 80),\n",
    "            1024: (237, 197, 63),\n",
    "            2048: (237, 194, 46),\n",
    "        }\n",
    "        return colors\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Render the board using pygame.\"\"\"\n",
    "        if self.rendering_mode != 'human':\n",
    "            return\n",
    "        self.screen.fill((187, 173, 160))  # Background color\n",
    "        for row in range(4):\n",
    "            for col in range(4):\n",
    "                value = self.board[row, col]\n",
    "                # Default color for large values\n",
    "                color = self.colors.get(value, (60, 58, 50))\n",
    "                rect = pygame.Rect(\n",
    "                    col * (self.cell_size + self.margin) + self.margin,\n",
    "                    row * (self.cell_size + self.margin) + self.margin,\n",
    "                    self.cell_size,\n",
    "                    self.cell_size\n",
    "                )\n",
    "                pygame.draw.rect(self.screen, color, rect)\n",
    "                if value != 0:\n",
    "                    text_surface = self.font.render(\n",
    "                        str(value), True, (119, 110, 101))\n",
    "                    text_rect = text_surface.get_rect(center=rect.center)\n",
    "                    self.screen.blit(text_surface, text_rect)\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the pygame window.\"\"\"\n",
    "        pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7992eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "\n",
    "class CnnModel(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: Box, features_dim: int = 128):\n",
    "        super(CnnModel, self).__init__(observation_space, features_dim)\n",
    "        \n",
    "        # Define the CNN layers\n",
    "        self.conv1 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(self.conv1.out_channels, 16, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        # Update the input size for fc1 based on the output of conv2\n",
    "        self.fc1 = nn.Linear(self.conv2.out_channels * 2 * 2, features_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)  # Change shape from (batch_size, 4, 4, 16) to (batch_size, 16, 4, 4)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "from stable_baselines3.common.policies import ActorCriticCnnPolicy\n",
    "\n",
    "class CustomCnnPolicy(ActorCriticCnnPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomCnnPolicy, self).__init__(*args, **kwargs, features_extractor_class=CnnModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd7b46bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_2048_tensorboard/PPO_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 135      |\n",
      "|    ep_rew_mean     | 1.01e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 553      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4096     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 146          |\n",
      "|    ep_rew_mean          | 1.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 344          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044776476 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.7e-05      |\n",
      "|    learning_rate        | 3e-05        |\n",
      "|    loss                 | 8.28e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    value_loss           | 1.64e+04     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 148           |\n",
      "|    ep_rew_mean          | 1.16e+03      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 308           |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 39            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077213615 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.38         |\n",
      "|    explained_variance   | 0.000352      |\n",
      "|    learning_rate        | 3e-05         |\n",
      "|    loss                 | 1.01e+04      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000247     |\n",
      "|    value_loss           | 2.18e+04      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "\n",
    "\n",
    "game = Board2048Renderer()\n",
    "# games = SubprocVecEnv([lambda: Monitor(Board2048Renderer()) for _ in range(4)])\n",
    "\n",
    "model = PPO(\n",
    "    policy = CustomCnnPolicy, \n",
    "    env = game, \n",
    "    verbose=1, \n",
    "    device='cuda', \n",
    "    tensorboard_log=\"./ppo_2048_tensorboard/\",\n",
    "    learning_rate=3e-5,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    ")\n",
    "model = model.learn(total_timesteps=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5cebb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score after 20 simulations: 1025.8\n",
      "Game Over!, Total Score is 1624\n"
     ]
    }
   ],
   "source": [
    "def main_loop(b: Board2048, direction: int):\n",
    "    new_board = b.move(direction)\n",
    "    moved = False\n",
    "    if (new_board == b.board).all():\n",
    "        # move is invalid\n",
    "        pass\n",
    "    else:\n",
    "        moved = True\n",
    "        b.board = new_board\n",
    "        b.fill_cell()\n",
    "    return moved\n",
    "\n",
    "\n",
    "scores = []\n",
    "repeat = 20\n",
    "for _ in range(repeat):\n",
    "  sim_game = Board2048Renderer(rendering_mode=None)\n",
    "  sim_finish = False\n",
    "  while not sim_finish:\n",
    "    sim_direction, _ = model.predict(sim_game.get_obs(), deterministic=True)\n",
    "    sim_moved = main_loop(sim_game, sim_direction)\n",
    "    while not sim_moved:\n",
    "      sim_moved = main_loop(sim_game, np.random.randint(0, 4))\n",
    "    sim_finish = sim_game.is_game_over()\n",
    "  scores.append(sim_game.total_score)\n",
    "mean_score = np.mean(scores)\n",
    "print(f\"Mean Score after {repeat} simulations:\", mean_score)\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "game = Board2048Renderer(rendering_mode='human')\n",
    "finish = False\n",
    "while not finish:\n",
    "  direction, _ = model.predict(game.get_obs(), deterministic=True)\n",
    "  # print(game.get_obs())\n",
    "  # print(direction)\n",
    "  moved = main_loop(game, direction)\n",
    "  while not moved:\n",
    "    moved = main_loop(game, np.random.randint(0, 4))\n",
    "    # print(\"Random move:\", moved)\n",
    "  # print(game.get_obs())\n",
    "  # print(game.total_score)\n",
    "  game.render()\n",
    "  finish = game.is_game_over()\n",
    "  pygame.time.wait(50)\n",
    "print(\"Game Over!, Total Score is {}\".format(game.total_score))\n",
    "game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5493466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import PPO\n",
    "# import numpy as np\n",
    "\n",
    "# # Define the parameter grid\n",
    "# params = {\n",
    "#     'learning_rate': [3e-3, 3e-4, 3e-5],\n",
    "#     'n_steps': [1024, 2048, 4096],\n",
    "#     'batch_size': [32, 64, 128],\n",
    "#     'n_epochs': [5, 10, 20],\n",
    "#     'gamma': [0.95, 0.99, 0.999],\n",
    "# }\n",
    "\n",
    "# # Function to test a single parameter\n",
    "\n",
    "\n",
    "# def test_param(param_name, param_values, fixed_params, total_timesteps=50_000):\n",
    "#     results = {}\n",
    "#     for value in param_values:\n",
    "#         print(f\"Testing {param_name}={value}\")\n",
    "#         fixed_params[param_name] = value\n",
    "\n",
    "#         # Create the environment\n",
    "#         env = Board2048Renderer(rendering_mode=None)\n",
    "\n",
    "#         # Create the model with the current parameter value\n",
    "#         model = PPO(\n",
    "#             policy=\"MlpPolicy\",\n",
    "#             env=env,\n",
    "#             verbose=0,\n",
    "#             device='cpu',\n",
    "#             tensorboard_log=f\"./ppo_2048_tensorboard/{param_name}_{value}/\",\n",
    "#             **fixed_params\n",
    "#         )\n",
    "\n",
    "#         # Train the model\n",
    "#         model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "\n",
    "# # Fixed parameters (default values for other parameters)\n",
    "# fixed_params = {\n",
    "#     'learning_rate': 3e-4,\n",
    "#     'n_steps': 2048,\n",
    "#     'batch_size': 64,\n",
    "#     'n_epochs': 10,\n",
    "#     'gamma': 0.99,\n",
    "# }\n",
    "\n",
    "# # Test learning rates\n",
    "# learning_rate_results = test_param(\n",
    "#     'learning_rate', params['learning_rate'], fixed_params)\n",
    "\n",
    "# # Test n_steps\n",
    "# n_steps_results = test_param('n_steps', params['n_steps'], fixed_params)\n",
    "\n",
    "# # Test batch_size\n",
    "# batch_size_results = test_param(\n",
    "#     'batch_size', params['batch_size'], fixed_params)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Learning Rate Results:\", learning_rate_results)\n",
    "# print(\"n_steps Results:\", n_steps_results)\n",
    "# print(\"Batch Size Results:\", batch_size_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sb3multi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
